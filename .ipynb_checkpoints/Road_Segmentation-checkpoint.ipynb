{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in sorted(glob.glob('path to train images')) : \n",
    "    for imagename in sorted(glob.glob(filename+'/*.png')) : \n",
    "      im=cv2.imread(imagename)\n",
    "      image_list.append(im)\n",
    "images_X=np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_y = []\n",
    "k=0\n",
    "for filename in sorted(glob.glob('path to train labels')) : \n",
    "    for imagename in sorted(glob.glob(filename+'/*.png')) : \n",
    "      k=k+1\n",
    "      im=cv2.imread(imagename,0)\n",
    "      image_list_y.append(im)\n",
    "images_Y=np.array(image_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_img = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "  ])\n",
    "\n",
    "class dataset(Dataset):\n",
    "  def __init__(self, images_X, images_Y, transform_img):\n",
    "    self.data=images_X\n",
    "    self.labels=images_Y\n",
    "    self.transform=transform_img\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    x = self.data[index]\n",
    "    y = self.labels[index]\n",
    "    x = self.transform(x)\n",
    "    y = y/255\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset(images_X=images_X, images_Y=images_Y, transform_img=transform_img)\n",
    "train_loader = DataLoader(train_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "\n",
    "class InitialBlock(nn.Module):\n",
    "    \"\"\"The initial block is composed of two branches:\n",
    "    1. a main branch which performs a regular convolution with stride 2;\n",
    "    2. an extension branch which performs max-pooling.\n",
    "    Doing both operations in parallel and concatenating their results\n",
    "    allows for efficient downsampling and expansion. The main branch\n",
    "    outputs 13 feature maps while the extension branch outputs 3, for a\n",
    "    total of 16 feature maps after concatenation.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number output channels.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - As stated above the number of output channels for this\n",
    "        # branch is the total minus 3, since the remaining channels come from\n",
    "        # the extension branch\n",
    "        self.main_branch = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels - 3,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=bias)\n",
    "\n",
    "        # Extension branch\n",
    "        self.ext_branch = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "\n",
    "        # Initialize batch normalization to be used after concatenation\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        main = self.main_branch(x)\n",
    "        ext = self.ext_branch(x)\n",
    "\n",
    "        # Concatenate branches\n",
    "        out = torch.cat((main, ext), 1)\n",
    "\n",
    "        # Apply batch normalization\n",
    "        out = self.batch_norm(out)\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class RegularBottleneck(nn.Module):\n",
    "    \"\"\"Regular bottlenecks are the main building block of ENet.\n",
    "    Main branch:\n",
    "    1. Shortcut connection.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution which decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. regular, dilated or asymmetric convolution;\n",
    "    3. 1x1 convolution which increases the number of channels back to\n",
    "    ``channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - channels (int): the number of input and output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to\n",
    "    ``channels`` used to compute the number of\n",
    "    channels after the projection. eg. given ``channels`` equal to 128 and\n",
    "    internal_ratio equal to 2 the number of channels after the projection\n",
    "    is 64. Default: 4.\n",
    "    - kernel_size (int, optional): the kernel size of the filters used in\n",
    "    the convolution layer described above in item 2 of the extension\n",
    "    branch. Default: 3.\n",
    "    - padding (int, optional): zero-padding added to both sides of the\n",
    "    input. Default: 0.\n",
    "    - dilation (int, optional): spacing between kernel elements for the\n",
    "    convolution described in item 2 of the extension branch. Default: 1.\n",
    "    asymmetric (bool, optional): flags if the convolution described in\n",
    "    item 2 of the extension branch is asymmetric or not. Default: False.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 internal_ratio=4,\n",
    "                 kernel_size=3,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 asymmetric=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}.\"\n",
    "                               .format(channels, internal_ratio))\n",
    "\n",
    "        internal_channels = channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - shortcut connection\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution, and,\n",
    "        # finally, a regularizer (spatial dropout). Number of channels is constant.\n",
    "\n",
    "        # 1x1 projection convolution\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels,\n",
    "                internal_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # If the convolution is asymmetric we split the main convolution in\n",
    "        # two. Eg. for a 5x5 asymmetric convolution we have two convolution:\n",
    "        # the first is 5x1 and the second is 1x5.\n",
    "        if asymmetric:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(kernel_size, 1),\n",
    "                    stride=1,\n",
    "                    padding=(padding, 0),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation(),\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=(1, kernel_size),\n",
    "                    stride=1,\n",
    "                    padding=(0, padding),\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "        else:\n",
    "            self.ext_conv2 = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    internal_channels,\n",
    "                    internal_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=1,\n",
    "                    padding=padding,\n",
    "                    dilation=dilation,\n",
    "                    bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after adding the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        main = x\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class DownsamplingBottleneck(nn.Module):\n",
    "    \"\"\"Downsampling bottlenecks further downsample the feature map size.\n",
    "    Main branch:\n",
    "    1. max pooling with stride 2; indices are saved to be used for\n",
    "    unpooling later.\n",
    "    Extension branch:\n",
    "    1. 2x2 convolution with stride 2 that decreases the number of channels\n",
    "    by ``internal_ratio``, also called a projection;\n",
    "    2. regular convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``channels``\n",
    "    used to compute the number of channels after the projection. eg. given\n",
    "    ``channels`` equal to 128 and internal_ratio equal to 2 the number of\n",
    "    channels after the projection is 64. Default: 4.\n",
    "    - return_indices (bool, optional):  if ``True``, will return the max\n",
    "    indices along with the outputs. Useful when unpooling later.\n",
    "    - dropout_prob (float, optional): probability of an element to be\n",
    "    zeroed. Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if\n",
    "    ``True``. Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 return_indices=False,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Store parameters that are needed later\n",
    "        self.return_indices = return_indices\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_max1 = nn.MaxPool2d(\n",
    "            2,\n",
    "            stride=2,\n",
    "            return_indices=return_indices)\n",
    "\n",
    "        # Extension branch - 2x2 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 2x2 projection convolution with stride 2\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                internal_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=bias), nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels,\n",
    "                out_channels,\n",
    "                kernel_size=1,\n",
    "                stride=1,\n",
    "                bias=bias), nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Main branch shortcut\n",
    "        if self.return_indices:\n",
    "            main, max_indices = self.main_max1(x)\n",
    "        else:\n",
    "            main = self.main_max1(x)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_conv3(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Main branch channel padding\n",
    "        n, ch_ext, h, w = ext.size()\n",
    "        ch_main = main.size()[1]\n",
    "        padding = torch.zeros(n, ch_ext - ch_main, h, w)\n",
    "\n",
    "        # Before concatenating, check if main is on the CPU or GPU and\n",
    "        # convert padding accordingly\n",
    "        if main.is_cuda:\n",
    "            padding = padding.cuda()\n",
    "\n",
    "        # Concatenate\n",
    "        main = torch.cat((main, padding), 1)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out), max_indices\n",
    "\n",
    "\n",
    "class UpsamplingBottleneck(nn.Module):\n",
    "    \"\"\"The upsampling bottlenecks upsample the feature map resolution using max\n",
    "    pooling indices stored from the corresponding downsampling bottleneck.\n",
    "    Main branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. max unpool layer using the max pool indices from the corresponding\n",
    "    downsampling max pool layer.\n",
    "    Extension branch:\n",
    "    1. 1x1 convolution with stride 1 that decreases the number of channels by\n",
    "    ``internal_ratio``, also called a projection;\n",
    "    2. transposed convolution (by default, 3x3);\n",
    "    3. 1x1 convolution which increases the number of channels to\n",
    "    ``out_channels``, also called an expansion;\n",
    "    4. dropout as a regularizer.\n",
    "    Keyword arguments:\n",
    "    - in_channels (int): the number of input channels.\n",
    "    - out_channels (int): the number of output channels.\n",
    "    - internal_ratio (int, optional): a scale factor applied to ``in_channels``\n",
    "     used to compute the number of channels after the projection. eg. given\n",
    "     ``in_channels`` equal to 128 and ``internal_ratio`` equal to 2 the number\n",
    "     of channels after the projection is 64. Default: 4.\n",
    "    - dropout_prob (float, optional): probability of an element to be zeroed.\n",
    "    Default: 0 (no dropout).\n",
    "    - bias (bool, optional): Adds a learnable bias to the output if ``True``.\n",
    "    Default: False.\n",
    "    - relu (bool, optional): When ``True`` ReLU is used as the activation\n",
    "    function; otherwise, PReLU is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 internal_ratio=4,\n",
    "                 dropout_prob=0,\n",
    "                 bias=False,\n",
    "                 relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # Check in the internal_scale parameter is within the expected range\n",
    "        # [1, channels]\n",
    "        if internal_ratio <= 1 or internal_ratio > in_channels:\n",
    "            raise RuntimeError(\"Value out of range. Expected value in the \"\n",
    "                               \"interval [1, {0}], got internal_scale={1}. \"\n",
    "                               .format(in_channels, internal_ratio))\n",
    "\n",
    "        internal_channels = in_channels // internal_ratio\n",
    "\n",
    "        if relu:\n",
    "            activation = nn.ReLU\n",
    "        else:\n",
    "            activation = nn.PReLU\n",
    "\n",
    "        # Main branch - max pooling followed by feature map (channels) padding\n",
    "        self.main_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "        # Remember that the stride is the same as the kernel_size, just like\n",
    "        # the max pooling layers\n",
    "        self.main_unpool1 = nn.MaxUnpool2d(kernel_size=2)\n",
    "\n",
    "        # Extension branch - 1x1 convolution, followed by a regular, dilated or\n",
    "        # asymmetric convolution, followed by another 1x1 convolution. Number\n",
    "        # of channels is doubled.\n",
    "\n",
    "        # 1x1 projection convolution with stride 1\n",
    "        self.ext_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, internal_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(internal_channels), activation())\n",
    "\n",
    "        # Transposed convolution\n",
    "        self.ext_tconv1 = nn.ConvTranspose2d(\n",
    "            internal_channels,\n",
    "            internal_channels,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            bias=bias)\n",
    "        self.ext_tconv1_bnorm = nn.BatchNorm2d(internal_channels)\n",
    "        self.ext_tconv1_activation = activation()\n",
    "\n",
    "        # 1x1 expansion convolution\n",
    "        self.ext_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                internal_channels, out_channels, kernel_size=1, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels), activation())\n",
    "\n",
    "        self.ext_regul = nn.Dropout2d(p=dropout_prob)\n",
    "\n",
    "        # PReLU layer to apply after concatenating the branches\n",
    "        self.out_activation = activation()\n",
    "\n",
    "    def forward(self, x, max_indices, output_size):\n",
    "        # Main branch shortcut\n",
    "        main = self.main_conv1(x)\n",
    "        main = self.main_unpool1(\n",
    "            main, max_indices, output_size=output_size)\n",
    "\n",
    "        # Extension branch\n",
    "        ext = self.ext_conv1(x)\n",
    "        ext = self.ext_tconv1(ext, output_size=output_size)\n",
    "        ext = self.ext_tconv1_bnorm(ext)\n",
    "        ext = self.ext_tconv1_activation(ext)\n",
    "        ext = self.ext_conv2(ext)\n",
    "        ext = self.ext_regul(ext)\n",
    "\n",
    "        # Add main and extension branches\n",
    "        out = main + ext\n",
    "\n",
    "        return self.out_activation(out)\n",
    "\n",
    "\n",
    "class ENet(nn.Module):\n",
    "    \"\"\"Generate the ENet model.\n",
    "    Keyword arguments:\n",
    "    - num_classes (int): the number of classes to segment.\n",
    "    - encoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the encoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: False.\n",
    "    - decoder_relu (bool, optional): When ``True`` ReLU is used as the\n",
    "    activation function in the decoder blocks/layers; otherwise, PReLU\n",
    "    is used. Default: True.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes, encoder_relu=False, decoder_relu=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.initial_block = InitialBlock(3, 16, relu=encoder_relu)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        self.downsample1_0 = DownsamplingBottleneck(\n",
    "            16,\n",
    "            64,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.01,\n",
    "            relu=encoder_relu)\n",
    "        self.regular1_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_3 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "        self.regular1_4 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.01, relu=encoder_relu)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        self.downsample2_0 = DownsamplingBottleneck(\n",
    "            64,\n",
    "            128,\n",
    "            return_indices=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.regular2_1 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_2 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_3 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_4 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular2_5 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated2_6 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric2_7 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated2_8 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        self.regular3_0 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_1 = RegularBottleneck(\n",
    "            128, dilation=2, padding=2, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_2 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            padding=2,\n",
    "            asymmetric=True,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_3 = RegularBottleneck(\n",
    "            128, dilation=4, padding=4, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.regular3_4 = RegularBottleneck(\n",
    "            128, padding=1, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.dilated3_5 = RegularBottleneck(\n",
    "            128, dilation=8, padding=8, dropout_prob=0.1, relu=encoder_relu)\n",
    "        self.asymmetric3_6 = RegularBottleneck(\n",
    "            128,\n",
    "            kernel_size=5,\n",
    "            asymmetric=True,\n",
    "            padding=2,\n",
    "            dropout_prob=0.1,\n",
    "            relu=encoder_relu)\n",
    "        self.dilated3_7 = RegularBottleneck(\n",
    "            128, dilation=16, padding=16, dropout_prob=0.1, relu=encoder_relu)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        self.upsample4_0 = UpsamplingBottleneck(\n",
    "            128, 64, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_1 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular4_2 = RegularBottleneck(\n",
    "            64, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        self.upsample5_0 = UpsamplingBottleneck(\n",
    "            64, 16, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.regular5_1 = RegularBottleneck(\n",
    "            16, padding=1, dropout_prob=0.1, relu=decoder_relu)\n",
    "        self.transposed_conv = nn.ConvTranspose2d(\n",
    "            16,\n",
    "            num_classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial block\n",
    "        input_size = x.size()\n",
    "        x = self.initial_block(x)\n",
    "\n",
    "        # Stage 1 - Encoder\n",
    "        stage1_input_size = x.size()\n",
    "        x, max_indices1_0 = self.downsample1_0(x)\n",
    "        x = self.regular1_1(x)\n",
    "        x = self.regular1_2(x)\n",
    "        x = self.regular1_3(x)\n",
    "        x = self.regular1_4(x)\n",
    "\n",
    "        # Stage 2 - Encoder\n",
    "        stage2_input_size = x.size()\n",
    "        x, max_indices2_0 = self.downsample2_0(x)\n",
    "        x = self.regular2_1(x)\n",
    "        x = self.dilated2_2(x)\n",
    "        x = self.asymmetric2_3(x)\n",
    "        x = self.dilated2_4(x)\n",
    "        x = self.regular2_5(x)\n",
    "        x = self.dilated2_6(x)\n",
    "        x = self.asymmetric2_7(x)\n",
    "        x = self.dilated2_8(x)\n",
    "\n",
    "        # Stage 3 - Encoder\n",
    "        x = self.regular3_0(x)\n",
    "        x = self.dilated3_1(x)\n",
    "        x = self.asymmetric3_2(x)\n",
    "        x = self.dilated3_3(x)\n",
    "        x = self.regular3_4(x)\n",
    "        x = self.dilated3_5(x)\n",
    "        x = self.asymmetric3_6(x)\n",
    "        x = self.dilated3_7(x)\n",
    "\n",
    "        # Stage 4 - Decoder\n",
    "        x = self.upsample4_0(x, max_indices2_0, output_size=stage2_input_size)\n",
    "        x = self.regular4_1(x)\n",
    "        x = self.regular4_2(x)\n",
    "\n",
    "        # Stage 5 - Decoder\n",
    "        x = self.upsample5_0(x, max_indices1_0, output_size=stage1_input_size)\n",
    "        x = self.regular5_1(x)\n",
    "        x = self.transposed_conv(x, output_size=input_size)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ENet(num_classes=2).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader,criterion,opt_func=torch.optim.Adam):\n",
    "\n",
    "    optim = opt_func(model.parameters(),lr=lr,weight_decay=2e-4)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for step, batch_data in enumerate(train_loader):\n",
    "\n",
    "            # Get the inputs and labels\n",
    "            inputs = batch_data[0].to('cuda')\n",
    "            labels = batch_data[1].to('cuda').long()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Loss computation\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backpropagation\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # Keep track of loss for current epoch\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print(\"[Step: %d] Iteration loss: %.4f\" % (step, loss.item()))\n",
    "        print(\"Epoch number:\",epoch,\" - Loss = \" , epoch_loss / len(train_loader) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(num_epochs, lr, model, train_loader, _ , criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import glob\n",
    "val_list = []\n",
    "k=0\n",
    "for filename in sorted(glob.glob('path to val images')) : \n",
    "    for imagename in sorted(glob.glob(filename+'/*.png')) : \n",
    "      k=k+1\n",
    "      if(k%10 == 0):\n",
    "        print(k)\n",
    "      im=cv2.imread(imagename)\n",
    "      val_list.append(im)\n",
    "val_X=np.array(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list_y = []\n",
    "k=0\n",
    "for filename in sorted(glob.glob('path to val labels')) : \n",
    "    for imagename in sorted(glob.glob(filename+'/*.png')) : \n",
    "      k=k+1\n",
    "      if(k%10 == 0):\n",
    "        print(k)\n",
    "      im=cv2.imread(imagename,0)\n",
    "      val_list_y.append(im)\n",
    "val_Y=np.array(val_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = dataset(images_X=val_X, images_Y=val_Y, transform_img=transform_img)\n",
    "val_loader = DataLoader(val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "iou = 0.0\n",
    "num = 0\n",
    "acc = 0.0\n",
    "for img,label in val_loader:\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  xb = to_device(img, 'cuda')\n",
    "  yb = model(xb)\n",
    "  _, preds  = torch.max(yb, dim=1)\n",
    "  preds = preds.cpu()\n",
    "\n",
    "  target = np.array(label.cpu())\n",
    "  prediction = np.array(preds)\n",
    "\n",
    "  intersection = np.logical_and(target, prediction)\n",
    "\n",
    "  if np.sum(target) != 0 :\n",
    "    accuracy = np.sum(intersection) / np.sum(target)\n",
    "    num += 1\n",
    "    acc += accuracy\n",
    "\n",
    "  union = np.logical_or(target, prediction)  \n",
    "\n",
    "  iou_score = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "  iou += iou_score\n",
    "\n",
    "  print(\"-Accuracy = %.2f , IOU = %.2f\" %(accuracy*100,iou_score))\n",
    "\n",
    "print(\"IOU = \",iou/500)\n",
    "print(\"Accuracy= \",(acc/num)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
